Hand Gesture Recognition Using Leap Motion (Infrared Images)
This project implements a deep learning-based hand gesture recognition system using grayscale infrared images captured from the Leap Motion controller. It classifies 10 different hand gestures in real-time via a webcam, enabling intuitive human-computer interaction.

ğŸ” Project Overview
ğŸ“¸ Input: Grayscale infrared images of hands performing gestures
ğŸ§  Model: Convolutional Neural Network (CNN) built using TensorFlow/Keras
ğŸ¯ Output: Real-time classification of gestures (e.g., palm, l, fist, etc.)
ğŸ¥ Interface: Real-time webcam gesture detection with on-screen prediction
ğŸ“ Dataset Info
Dataset: Leap Motion Hand Gesture Dataset (Infrared)
Source: LeapGestRecog (https://www.kaggle.com/datasets/gti-upm/leapgestrecog)
Structure: leapGestRecog/ â”œâ”€â”€ 00/ â”‚ â”œâ”€â”€ 01_palm/ â”‚ â”œâ”€â”€ 02_l/ â”œâ”€â”€ ... â”œâ”€â”€ 09/
10 subjects (folders 00â€“09)
10 different gesture classes (e.g., palm, l, fist, down, etc.)
Format: Grayscale .png images
ğŸ›  Installation
Install all dependencies: pip install tensorflow opencv-python scikit-learn joblib matplotlib

ğŸ§  Model Training
To train the CNN model: python train_gesture_model.py

Saves the model as gesture_model.h5
Saves label encoder as label_encoder.pkl
Outputs training accuracy plot training_accuracy.png
ğŸ¥ Real-Time Prediction
To run the webcam-based gesture recognition: python predict.py

Opens webcam feed
Displays predicted gesture label on-screen
Press ESC to quit
ğŸ—‚ File Structure
. â”œâ”€â”€ gesture_model.h5 # Trained CNN model (HDF5 format) â”œâ”€â”€ label_encoder.pkl # Encoded class labels â”œâ”€â”€ train_gesture_model.py # Script for training the model â”œâ”€â”€ predict.py # Real-time prediction with webcam â”œâ”€â”€ training_accuracy.png # Accuracy plot â”œâ”€â”€ README.txt # Project documentation

ğŸ“ˆ Performance
âœ… Achieved validation accuracy: 99.96%
ğŸ“‰ No signs of overfitting
ğŸš€ Model generalizes well across subjects


ğŸ“š Future Work
Add gesture-based control for media/apps
Enable voice output for recognized gestures
Deploy the model using Flask or Streamlit
